{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T15:21:27.787539Z",
     "start_time": "2019-03-31T15:21:22.850446Z"
    },
    "code_folding": [
     3,
     21,
     28,
     45,
     59,
     79
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "import traceback\n",
    "\n",
    "from LSTM_for_Stock.model import SequentialModel\n",
    "from LSTM_for_Stock.data_processor import DataHelper\n",
    "from LSTM_for_Stock.data_processor import DataLoaderStock\n",
    "import logging\n",
    "from LSTM_for_Stock.data_processor import Wrapper\n",
    "from LSTM_for_Stock.data_processor import Wrapper_fillna\n",
    "import numpy as np\n",
    "from LSTM_for_Stock.unit import PlotHelper\n",
    "import pandas as pd\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "class wrapper(Wrapper):\n",
    "    def build(self, df):\n",
    "        result = df.copy()\n",
    "        result = result.fillna(method='ffill')\n",
    "        result = result.drop(columns=['up_count', 'down_count'])\n",
    "        return result.dropna()\n",
    "    \n",
    "class normalize(object):\n",
    "    \"\"\"数据标准化器\"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def build(self, df):\n",
    "        \"\"\"执行数据标准化。**数据归一化**。\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame 或 pd.Series): 待处理的数据。\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame 或 pd.Series: 与传入类型一致。\n",
    "        \"\"\"\n",
    "        return np.round(df / df.iloc[0],8)\n",
    "    \n",
    "def save_model(m:keras.models.Model, p: str = None, *args, **kwargs):\n",
    "    if p is None:\n",
    "        p = os.path.join(nb_dir,'train_result')\n",
    "    window = kwargs.pop('window', None)\n",
    "    days = kwargs.pop('days', None)\n",
    "    stockcode = kwargs.pop('stockcode', None)\n",
    "    if stockcode is None or window is None or days is None:\n",
    "        raise ValueError()\n",
    "    filename='model_{2}_{0:02d}_{1:02d}.h5'.format(window,days,stockcode)\n",
    "    p = os.path.join(p, filename)\n",
    "    os.makedirs(os.path.dirname(p),exist_ok=True)\n",
    "    m.save(p)\n",
    "    return p\n",
    "\n",
    "def save_history_img(history, p: str = None, *args, **kwargs):\n",
    "    if p is None:\n",
    "        p = os.path.join(nb_dir,'train_result')\n",
    "    window = kwargs.pop('window', None)\n",
    "    days = kwargs.pop('days', None)\n",
    "    benchmark = kwargs.pop('benchmark', None)\n",
    "    stockcode = kwargs.pop('stockcode', None)\n",
    "    filename='history_{2}_{0:02d}_{1:02d}.svg'.format(window,days,stockcode)\n",
    "    save_path = os.path.join(p, filename)\n",
    "    os.makedirs(os.path.dirname(save_path),exist_ok=True)\n",
    "    PlotHelper.plot_history(\n",
    "            history,\n",
    "            stockcode=stockcode,\n",
    "            benchmark=benchmark,\n",
    "            window=window,\n",
    "            days=days,\n",
    "            show=False,\n",
    "            save_path=save_path)\n",
    "    return save_path\n",
    "\n",
    "def do(code,window,days,*args,**kwargs):\n",
    "    print('{0} - {1:02d} - {2:02d} Start.'.format(code,window,days))\n",
    "    dl = DataLoaderStock(code, wrapper=wrapper())\n",
    "    df = dl.load()\n",
    "    train, test = DataHelper.train_test_split(df, batch_size=window + days)\n",
    "\n",
    "    X_train, Y_train = DataHelper.xy_split_2(train, window, days,norm=normalize())\n",
    "    X_test, Y_test = DataHelper.xy_split_2(test, window, days,norm=normalize())\n",
    "\n",
    "    X_train_arr = []\n",
    "    Y_train_arr = []\n",
    "    for x in X_train:\n",
    "        X_train_arr.append(x.values)\n",
    "    for y in Y_train:\n",
    "        Y_train_arr.append(y.values)\n",
    "    X_test_arr = []\n",
    "    Y_test_arr = []\n",
    "    for x in X_test:\n",
    "        X_test_arr.append(x.values)\n",
    "    for y in Y_test:\n",
    "        Y_test_arr.append(y.values)\n",
    "        \n",
    "    layers = [\n",
    "    {'units': 100,'type': 'lstm','input_shape': X_train_arr[0].shape,'return_sequences':True}, \n",
    "    {'type': 'dropout','rate':0.15}, \n",
    "    {'units': 200,'type': 'lstm','input_shape': X_train_arr[0].shape,'return_sequences':True}, \n",
    "    {'type': 'dropout','rate':0.15}, \n",
    "    {'units': 100,'type': 'lstm','input_shape': X_train_arr[0].shape,'return_sequences':False}, \n",
    "    {'units': days,'type': 'dense'}]\n",
    "    complie = {\n",
    "    #     \"optimizer\":\"adam\",\n",
    "        \"loss\":\"mse\",\n",
    "        \"optimizer\":\"rmsprop\",\n",
    "    #     \"loss\":\"categorical_crossentropy\",\n",
    "        \"metrics\": [\n",
    "            \"mae\", \"acc\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    model = SequentialModel()\n",
    "    model.build_model(layers, complie)\n",
    "    history = model.train(\n",
    "        np.array(X_train_arr),\n",
    "        np.array(Y_train_arr),\n",
    "        train={\n",
    "            'epochs': kwargs.pop(\"train_train_epochs\",1000),\n",
    "            'verbose': kwargs.pop(\"train_verbose\",0),\n",
    "            'validation_split': kwargs.pop(\"train_valid_split\",0.15)\n",
    "        })\n",
    "    save_path=save_model(model.model,stockcode=code,window=window,days=days)\n",
    "    print('model saved:'+save_path)\n",
    "    his_image_path=save_history_img(history,stockcode=code,window=window,days=days,benchmark=dl.benchmark_code)\n",
    "    print('history image:'+his_image_path)\n",
    "    \n",
    "    pred_slope = model.predict(np.array(X_test_arr))\n",
    "    df_result=pd.DataFrame({'pred':pred_slope[:,-1],'real':np.array(Y_test_arr)[:,-1]})\n",
    "    save_path=os.path.join(os.path.join(nb_dir,'train_result'), 'pred_{2}_{0:02d}_{1:02d}.csv'.format(window,days,code))\n",
    "    os.makedirs(os.path.dirname(save_path),exist_ok=True)\n",
    "    df_result.to_csv(save_path, encoding=\"utf-8\")\n",
    "    print('pred result dataframe:'+save_path)\n",
    "    \n",
    "    plt.figure(figsize=(15,8))\n",
    "    save_path=os.path.join(os.path.join(nb_dir,'train_result'), 'pred_{2}_{0:02d}_{1:02d}.svg'.format(window,days,code))\n",
    "    os.makedirs(os.path.dirname(save_path),exist_ok=True)\n",
    "    plt.plot(df_result['pred'])\n",
    "    plt.plot(df_result['real'])\n",
    "    plt.savefig(save_path, format=\"svg\")\n",
    "    print('pred result image:'+save_path)\n",
    "    print('{0} - {1:02d} - {2:02d} Done.'.format(code,window,days))\n",
    "    print(\"\".join(['-' for i in range(50)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T19:25:50.109019Z",
     "start_time": "2019-03-31T19:23:50.309952Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005-04-08\n",
      "000001 - 03 - 03 Start.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-c133a389a6b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mstock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mQA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQA_fetch_stock_day_adv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'1990-01-01'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'2019-03-31'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m<=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mdo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mdo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mdo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-7a9de72b04d0>\u001b[0m in \u001b[0;36mdo\u001b[1;34m(code, window, days, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[1;34m'epochs'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train_train_epochs\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[1;34m'verbose'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train_verbose\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m             \u001b[1;34m'validation_split'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train_valid_split\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m         })\n\u001b[0;32m    129\u001b[0m     \u001b[0msave_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstockcode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdays\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\LSTM-for-Stock\\LSTM_for_Stock\\model.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, X, Y, train, callbacks)\u001b[0m\n\u001b[0;32m    115\u001b[0m             \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__history\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\finance35\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\finance35\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\finance35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\finance35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\finance35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from QUANTAXIS import QA_fetch_stock_list\n",
    "import QUANTAXIS as QA\n",
    "import pandas as pd\n",
    "\n",
    "lst = QA.QA_fetch_stock_list_adv().code.values\n",
    "\n",
    "index=QA.QA_fetch_index_day_adv('399300', start='1990-01-01', end='2019-03-31')\n",
    "print(index.date[0].date())\n",
    "\n",
    "valid_lst=[]\n",
    "for code in lst:\n",
    "    stock=QA.QA_fetch_stock_day_adv(code, start='1990-01-01', end='2019-03-31')\n",
    "    if stock.date[0].date()<=index.date[0].date():\n",
    "        do(code,3,3)\n",
    "        do(code,5,3)\n",
    "        do(code,10,3)\n",
    "#         do(code,10,5)\n",
    "        do(code,15,3)\n",
    "#         do(code,15,5)\n",
    "#         do(code,15,10)\n",
    "        do(code,30,3)\n",
    "#         do(code,30,5)\n",
    "#         do(code,30,10)\n",
    "#         do(code,30,15)\n",
    "    else:\n",
    "        print(\"SKIP:\"+code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "finance_py_35",
   "language": "python",
   "name": "finance35"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
