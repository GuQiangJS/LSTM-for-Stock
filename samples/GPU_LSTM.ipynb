{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "import traceback\n",
    "\n",
    "from LSTM_for_Stock.model import SequentialModel\n",
    "from LSTM_for_Stock.data_processor import DataHelper\n",
    "from LSTM_for_Stock.data_processor import DataLoaderStock\n",
    "import logging\n",
    "from LSTM_for_Stock.data_processor import Wrapper\n",
    "from LSTM_for_Stock.data_processor import Wrapper_fillna\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM,CuDNNLSTM\n",
    "from keras.backend import clear_session\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "class Wrapper_default(Wrapper):\n",
    "    def build(self, df):\n",
    "        result = df.copy()\n",
    "        result = result.fillna(method='ffill')\n",
    "        result = result.drop(columns=['up_count', 'down_count'])\n",
    "        return result.dropna()\n",
    "    \n",
    "class normalize_default(object):\n",
    "    \"\"\"数据标准化器\"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def build(self, df):\n",
    "        \"\"\"执行数据标准化。**数据归一化**。\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame 或 pd.Series): 待处理的数据。\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame 或 pd.Series: 与传入类型一致。\n",
    "        \"\"\"\n",
    "        return np.round(df / df.iloc[0],8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "code='000002'\n",
    "window=5\n",
    "days=3\n",
    "dl = DataLoaderStock(code, Wrapper_default=Wrapper_default())\n",
    "df = dl.load()\n",
    "train, test = DataHelper.train_test_split(df, batch_size=window + days)\n",
    "\n",
    "X_train, Y_train = DataHelper.xy_split_2(train, window, days,norm=normalize_default())\n",
    "X_test, Y_test = DataHelper.xy_split_2(test, window, days,norm=normalize_default())\n",
    "\n",
    "X_train_arr = []\n",
    "Y_train_arr = []\n",
    "for x in X_train:\n",
    "    X_train_arr.append(x.values)\n",
    "for y in Y_train:\n",
    "    Y_train_arr.append(y.values)\n",
    "X_test_arr = []\n",
    "Y_test_arr = []\n",
    "for x in X_test:\n",
    "    X_test_arr.append(x.values)\n",
    "for y in Y_test:\n",
    "    Y_test_arr.append(y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2497 samples, validate on 441 samples\n",
      "Epoch 1/5\n",
      " - 8s - loss: 0.1135 - mean_absolute_error: 0.2312 - acc: 0.3440 - val_loss: 0.0172 - val_mean_absolute_error: 0.1122 - val_acc: 0.1814\n",
      "Epoch 2/5\n",
      " - 2s - loss: 0.0308 - mean_absolute_error: 0.1401 - acc: 0.3148 - val_loss: 0.0179 - val_mean_absolute_error: 0.1142 - val_acc: 0.5805\n",
      "Epoch 3/5\n",
      " - 2s - loss: 0.0263 - mean_absolute_error: 0.1292 - acc: 0.3416 - val_loss: 0.0073 - val_mean_absolute_error: 0.0609 - val_acc: 0.5805\n",
      "Epoch 4/5\n",
      " - 2s - loss: 0.0236 - mean_absolute_error: 0.1232 - acc: 0.3364 - val_loss: 0.0072 - val_mean_absolute_error: 0.0605 - val_acc: 0.5805\n",
      "Epoch 5/5\n",
      " - 2s - loss: 0.0231 - mean_absolute_error: 0.1214 - acc: 0.3268 - val_loss: 0.0167 - val_mean_absolute_error: 0.1087 - val_acc: 0.5601\n",
      "Net time using LSTM :  21.55772042274475  secs.\n"
     ]
    }
   ],
   "source": [
    "clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=X_train_arr[0].shape, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(days))\n",
    "model.compile(loss='mse',\n",
    "             optimizer=\"rmsprop\",\n",
    "             metrics=[\"mae\", \"acc\"])\n",
    "start = time.time()\n",
    "history = model.fit(\n",
    "    np.array(X_train_arr),\n",
    "    np.array(Y_train_arr),\n",
    "    epochs=5,\n",
    "    verbose=2,\n",
    "    batch_size=128,\n",
    "    validation_split=0.15\n",
    ")\n",
    "end = time.time()\n",
    "print('Net time using LSTM : ', end-start, ' secs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "finance_py_35",
   "language": "python",
   "name": "finance35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
