{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "import traceback\n",
    "\n",
    "from LSTM_for_Stock.model import SequentialModel\n",
    "from LSTM_for_Stock.data_processor import DataHelper\n",
    "from LSTM_for_Stock.data_processor import DataLoaderStock\n",
    "import logging\n",
    "from LSTM_for_Stock.data_processor import Wrapper\n",
    "from LSTM_for_Stock.data_processor import Wrapper_fillna\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM,CuDNNLSTM\n",
    "from keras.backend import clear_session\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "class wrapper(Wrapper):\n",
    "    def build(self, df):\n",
    "        result = df.copy()\n",
    "        result = result.fillna(method='ffill')\n",
    "        result = result.drop(columns=['up_count', 'down_count'])\n",
    "        return result.dropna()\n",
    "    \n",
    "class normalize(object):\n",
    "    \"\"\"数据标准化器\"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def build(self, df):\n",
    "        \"\"\"执行数据标准化。**数据归一化**。\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame 或 pd.Series): 待处理的数据。\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame 或 pd.Series: 与传入类型一致。\n",
    "        \"\"\"\n",
    "        return np.round(df / df.iloc[0],8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "code='000002'\n",
    "window=5\n",
    "days=3\n",
    "dl = DataLoaderStock(code, wrapper=wrapper())\n",
    "df = dl.load()\n",
    "train, test = DataHelper.train_test_split(df, batch_size=window + days)\n",
    "\n",
    "X_train, Y_train = DataHelper.xy_split_2(train, window, days,norm=normalize())\n",
    "X_test, Y_test = DataHelper.xy_split_2(test, window, days,norm=normalize())\n",
    "\n",
    "X_train_arr = []\n",
    "Y_train_arr = []\n",
    "for x in X_train:\n",
    "    X_train_arr.append(x.values)\n",
    "for y in Y_train:\n",
    "    Y_train_arr.append(y.values)\n",
    "X_test_arr = []\n",
    "Y_test_arr = []\n",
    "for x in X_test:\n",
    "    X_test_arr.append(x.values)\n",
    "for y in Y_test:\n",
    "    Y_test_arr.append(y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2497 samples, validate on 441 samples\n",
      "Epoch 1/5\n",
      " - 7s - loss: 0.0964 - mean_absolute_error: 0.2138 - acc: 0.3332 - val_loss: 0.0215 - val_mean_absolute_error: 0.1281 - val_acc: 0.2336\n",
      "Epoch 2/5\n",
      " - 1s - loss: 0.0273 - mean_absolute_error: 0.1323 - acc: 0.3236 - val_loss: 0.0086 - val_mean_absolute_error: 0.0704 - val_acc: 0.5782\n",
      "Epoch 3/5\n",
      " - 1s - loss: 0.0286 - mean_absolute_error: 0.1352 - acc: 0.3400 - val_loss: 0.0066 - val_mean_absolute_error: 0.0555 - val_acc: 0.5442\n",
      "Epoch 4/5\n",
      " - 1s - loss: 0.0227 - mean_absolute_error: 0.1208 - acc: 0.3356 - val_loss: 0.0052 - val_mean_absolute_error: 0.0477 - val_acc: 0.1791\n",
      "Epoch 5/5\n",
      " - 1s - loss: 0.0233 - mean_absolute_error: 0.1203 - acc: 0.3224 - val_loss: 0.0052 - val_mean_absolute_error: 0.0474 - val_acc: 0.2381\n",
      "Net time using CuDNNLSTM :  10.926363229751587  secs.\n"
     ]
    }
   ],
   "source": [
    "clear_session()\n",
    "model = Sequential()\n",
    "model.add(CuDNNLSTM(128, input_shape=X_train_arr[0].shape, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(CuDNNLSTM(64))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(days))\n",
    "model.compile(loss='mse',\n",
    "             optimizer=\"rmsprop\",\n",
    "             metrics=[\"mae\", \"acc\"])\n",
    "start = time.time()\n",
    "history = model.fit(\n",
    "    np.array(X_train_arr),\n",
    "    np.array(Y_train_arr),\n",
    "    epochs=5,\n",
    "    verbose=2,\n",
    "    batch_size=128,\n",
    "    validation_split=0.15\n",
    ")\n",
    "end = time.time()\n",
    "print('Net time using CuDNNLSTM : ', end-start, ' secs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finance_py_35",
   "language": "python",
   "name": "finance35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
